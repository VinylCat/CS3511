{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import subprocess\n",
    "from glob import glob\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import measure\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.ndimage as ndi\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import model_zoo\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "    \n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        num_classes = 5\n",
    "        self.label_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "        self.relu_ = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.emb = nn.Embedding(num_classes, num_classes)\n",
    "        self.emb.weight = nn.Parameter(torch.eye(num_classes))\n",
    "        \n",
    "#         self.emb_mask = nn.Embedding(num_classes, num_classes)\n",
    "#         self.emb_mask.weight =  nn.Parameter(torch.Tensor([\n",
    "#             [1,1,0,0,0],\n",
    "#             [1,1,1,0,0],\n",
    "#             [0,1,1,1,0],\n",
    "#             [0,0,1,1,1],\n",
    "#             [0,0,0,1,1]]))\n",
    "#         self.emb_mask.weight.requires_grad_(False)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x2 = x\n",
    "        x = self.last_linear(x)\n",
    "        x2 = self.label_linear(x2.detach())\n",
    "        return x, x2\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x = self.features(x)\n",
    "        x, x2 = self.logits(x)\n",
    "        if targets is not None:\n",
    "            tar = self.emb(targets).cuda()\n",
    "#             tar = tar * (self.emb_mask(targets).cuda())\n",
    "        else:\n",
    "            tar=None\n",
    "        return x, x2, tar, self.emb.weight\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    \n",
    "    pretrained_dict=model_zoo.load_url(settings['url'])\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    # model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "#     if pretrained is not None:\n",
    "#         settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "#         initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "53a8b618f2032e72",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_modified_model(model_name='se_resnext50_32x4d', num_outputs=None, pretrained=True, \n",
    "            freeze_bn=False, dropout_p=0, **kwargs):\n",
    "    model=se_resnext50_32x4d()\n",
    "    model.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    in_features = model.last_linear.in_features\n",
    "        \n",
    "    if dropout_p == 0:\n",
    "        model.last_linear = nn.Linear(in_features, num_outputs)\n",
    "    else:\n",
    "        model.last_linear = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(in_features, num_outputs))\n",
    "    if freeze_bn:\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.requires_grad = False\n",
    "                m.bias.requires_grad = False\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c75c6331a0672cac",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metirc"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f14a75dc3fa6eb1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RAdam(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y_pred, y_true):\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.data.cpu().numpy()\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.data.cpu().numpy()\n",
    "    if y_pred.shape[1] == 1:\n",
    "        y_pred = y_pred[:, 0]\n",
    "    else:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    return metrics.cohen_kappa_score(y_pred, y_true, weights='quadratic')\n",
    "\n",
    "def comp_Loss(out1, out2, tar, emb_w, targets):\n",
    "    \"\"\"Compute the total loss\"\"\"\n",
    "    out2_prob = F.softmax(out2, dim=1)\n",
    "    tau2_prob = F.softmax(out2 / 2., dim=1).detach()\n",
    "    soft_tar = F.softmax(tar, dim=1).detach()# + 0.5*F.softmax(tar1).detach()\n",
    "#     soft_tar = (tar/torch.sum(tar, dim=1).unsqueeze(1)).detach()\n",
    "    L_o1_y = F.cross_entropy(out1, targets)\n",
    "\n",
    "    alpha = 0.9 # default:0.9\n",
    "    beta = 0.5 # default:0.5#adjust_alpha(epoch)\n",
    "    _, pred = torch.max(out2,1)\n",
    "    mask = pred.eq(targets).float().detach()\n",
    "    L_o1_emb = -torch.mean(my_loss(out1, soft_tar))\n",
    "\n",
    "    L_o2_y = F.cross_entropy(out2, targets)\n",
    "    L_emb_o2 = -torch.sum(my_loss(tar, tau2_prob)*mask)/(torch.sum(mask)+1e-8)\n",
    "    gap = torch.gather(out2_prob, 1, targets.view(-1,1))-alpha\n",
    "    L_re = torch.sum(F.relu(gap))\n",
    "    #L2_loss = F.mse_loss(emb_w.t(), emb_w.detach())\n",
    "    \n",
    "    loss = beta*L_o1_y + (1-beta)*L_o1_emb +L_o2_y +L_emb_o2 +L_re\n",
    "    return loss\n",
    "\n",
    "def my_loss(logit, prob):\n",
    "    \"\"\" Cross-entropy function\"\"\"\n",
    "    soft_logit = F.log_softmax(logit, dim=1)\n",
    "    loss = torch.sum(prob*soft_logit, 1)\n",
    "    return loss\n",
    "\n",
    "def compute_accuracy(y_pred,y_true):\n",
    "    if torch.is_tensor(y_pred):\n",
    "        y_pred = y_pred.data.cpu().numpy()\n",
    "    if torch.is_tensor(y_true):\n",
    "        y_true = y_true.data.cpu().numpy()\n",
    "    if y_pred.shape[1] == 1:\n",
    "        y_pred = y_pred[:, 0]\n",
    "    else:\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "    return metrics.accuracy_score(y_true, y_pred, normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b442f403649ff0ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def my_train(train_loader, model, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    ac_scores = AverageMeter()\n",
    "    print(f'here4')\n",
    "    model.train()\n",
    "\n",
    "    for i, (input, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        print(f'here5')\n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input, target)\n",
    "        print(f'here6')\n",
    "        out1, out2, tar, emb_w = output\n",
    "        \n",
    "        loss = comp_Loss(out1, out2, tar, emb_w, target)\n",
    "        # compute gradient and do optimizing step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        score = quadratic_weighted_kappa(out1, target)\n",
    "        ac_score = compute_accuracy(out1, target)\n",
    "\n",
    "        print(f'here7')\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        scores.update(score, input.size(0))\n",
    "        ac_scores.update(ac_score, input.size(0))\n",
    "\n",
    "    return losses.avg, scores.avg, ac_scores.avg\n",
    "\n",
    "def my_validate(val_loader, model, criterion):\n",
    "    losses = AverageMeter()\n",
    "    scores = AverageMeter()\n",
    "    ac_scores = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in tqdm(enumerate(val_loader), total=len(val_loader)):\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            output = model(input, target)\n",
    "            out1, out2, tar, emb_w = output\n",
    "\n",
    "            loss = comp_Loss(out1, out2, tar, emb_w, target)\n",
    "\n",
    "            score = quadratic_weighted_kappa(out1, target)\n",
    "            ac_score = compute_accuracy(out1, target)\n",
    "\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            scores.update(score, input.size(0))\n",
    "            ac_scores.update(ac_score, input.size(0))\n",
    "\n",
    "    return losses.avg, scores.avg, ac_scores.avg"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2f55f282125f4fd",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "### Transform"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2e3865abb5a9384"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "l1_probs = {}\n",
    "\n",
    "class CustomGaussianBlurWeighted(object):\n",
    "    \"\"\"对图像应用加权和高斯模糊的转换\"\"\"\n",
    "    def __call__(self, pic):\n",
    "        # 将PIL Image转换为NumPy数组\n",
    "        img = np.array(pic)\n",
    "\n",
    "        # 应用cv2.addWeighted操作\n",
    "        img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), 8), -4, 128)\n",
    "\n",
    "        # 将处理后的NumPy数组转换回PIL Image\n",
    "        return transforms.ToPILImage()(img)\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '()'\n",
    "\n",
    "class CustomMedianBlurWeighted(object):\n",
    "    def __call__(self, pic):\n",
    "        img = np.array(pic)\n",
    "        k = np.max(img.shape)//20*2 + 1\n",
    "        img = cv2.addWeighted(img, 4, cv2.medianBlur(img, k), -4, 128)\n",
    "        return transforms.ToPILImage()(img)\n",
    "\n",
    "train_transform = []\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    CustomGaussianBlurWeighted(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    CustomGaussianBlurWeighted(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5abfe8a9a4b654b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = ImageFolder('train', transform=train_transform)\n",
    "k_folds = 5  # 设定折数\n",
    "print('Training process initialize.')\n",
    "num_epochs = 10 \n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "model = get_modified_model(model_name='se_resnext50_32x4d', num_outputs=2, pretrained=False, freeze_bn=True, dropout_p=0)\n",
    "print(f'here1')\n",
    "def load_model_weights(model, model_path):\n",
    "    pretrained_dict = torch.load(model_path)\n",
    "    model_dict = model.state_dict()\n",
    "    \n",
    "    # 只保留存在于当前模型中的权重，并确保尺寸匹配\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and model_dict[k].size() == v.size()}\n",
    "    \n",
    "    # 更新当前模型的权重\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "load_model_weights(model, './model/se_resnext50_32x4d-a260b3a4.pth')\n",
    "model = model.cuda()  # 如果使用GPU\n",
    "\n",
    "print(next(model.parameters()).device)  \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(f'here2')\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # 分割数据集\n",
    "    train_subset = Subset(dataset, train_ids)\n",
    "    test_subset = Subset(dataset, test_ids)\n",
    "    print(f'here3')\n",
    "    # 创建数据加载器\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(test_subset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 在这里训练和验证模型\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_score, train_ac_score = my_train(train_loader, model, criterion, optimizer, epoch)\n",
    "        val_loss, val_score, val_ac_score = my_validate(val_loader, model, criterion)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Score: {train_score:.4f}, Val Score: {val_score:.4f}')\n",
    "\n",
    "        # 检查是否有最佳模型\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_score = val_score\n",
    "            torch.save(model.state_dict(), f'./new_model/model_fold_{fold+1}_best.pth')\n",
    "            print(f'Best Model for Fold {fold+1} Saved')\n",
    " \n",
    "    print(f'Best Loss for Fold {fold+1}: {best_loss:.4f}, Best Score: {best_score:.4f}')\n",
    "\n",
    "\n",
    "print('Training process has finished.')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7cd7a53557bdcca5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7eca7e853e29349d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
